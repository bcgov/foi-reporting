{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5066fd-ef21-4d97-8d9d-e45749e4fa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python\n",
    "%pip install boto3\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.insert(0, '/Workspace/Shared')\n",
    "import etl_helpers \n",
    "print(etl_helpers.__file__)\n",
    "from pyspark.sql.functions import collect_list, concat_ws, udf, lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from datetime import datetime, timedelta, date, time\n",
    "%pip install holidays\n",
    "%pip install maya\n",
    "import holidays\n",
    "import maya\n",
    "\n",
    "def __getholidaysbyyear(year):        \n",
    "    ca_holidays = []\n",
    "    for date, name in sorted(holidays.CA(prov='BC', years=year).items()):\n",
    "        ca_holidays.append(date.strftime('%Y-%m-%d'))\n",
    "    return ca_holidays    \n",
    "\n",
    "def getholidays():\n",
    "    ca_holidays = []\n",
    "    currentyear = datetime.today().year\n",
    "    years = [currentyear - 1, currentyear, currentyear + 1] \n",
    "    for year in years:\n",
    "        ca_holidays.extend(__getholidaysbyyear(year))\n",
    "    return ca_holidays\n",
    "\n",
    "def isbusinessday(inpdate, holidays=None):\n",
    "    _holidays = getholidays() if holidays is None else holidays\n",
    "    if formatdate(inpdate) not in _holidays and __isweekday(inpdate) == True:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def __isweekday( inpdate):\n",
    "    _inpdate = getdate(inpdate)\n",
    "    if _inpdate.weekday() < 5:\n",
    "        return True\n",
    "    else:   \n",
    "        return False \n",
    "    \n",
    "def getbusinessdaysbetween( date1, date2=None):\n",
    "    _holidays = getholidays()\n",
    "    businessdays = 0\n",
    "    date2 = date2 if date2 not in (None, '') else gettoday()\n",
    "    _date1_date_fmt = getdate(date1)\n",
    "    _date2_date_fmt = getdate(date2)\n",
    "    __fromdate = _date1_date_fmt if _date1_date_fmt <= _date2_date_fmt else _date2_date_fmt\n",
    "    __todate = _date2_date_fmt if _date2_date_fmt >= _date1_date_fmt else _date1_date_fmt\n",
    "    __fromcalcdate =__fromdate\n",
    "    while getdate(__fromcalcdate).date() < getdate(__todate).date():\n",
    "        if isbusinessday(__fromcalcdate, _holidays) == True:\n",
    "            businessdays += 1\n",
    "        __fromcalcdate =  __fromcalcdate + timedelta(days=1)           \n",
    "    return businessdays  \n",
    "\n",
    "def getdate(inputdate):\n",
    "    print(\"here3\")\n",
    "    return  datetime.strptime(inputdate, \"%Y-%m-%d\") if isinstance(inputdate, str) else datetime.combine(inputdate, time.min) if isinstance(inputdate, date) else inputdate   \n",
    "    # return datetime.strptime(inputdate, \"%Y-%m-%d\") if isinstance(inputdate, str) else inputdate   \n",
    "\n",
    "\n",
    "def gettoday(format=None):\n",
    "    now_pst = maya.parse(maya.now()).datetime(to_timezone='America/Vancouver', naive=False)\n",
    "    return __formatdate(now_pst, format)\n",
    "\n",
    "def formatdate( input, format=None):\n",
    "    _inpdate =  getdate(input)\n",
    "    return __formatdate(_inpdate, format) \n",
    "\n",
    "def __formatdate(_inpdate, format):\n",
    "    _format = format if format not in (None, '') else \"%Y-%m-%d\"\n",
    "    return _inpdate.strftime(_format)\n",
    "\n",
    "runcycleid = etl_helpers.start_run_cycle(\"factRequestForDocuments\")\n",
    "\n",
    "try:\n",
    "\n",
    "    df_existing = spark.sql(\"SELECT max(TIMESTAMP(runcycleendat)) as runcycleendat from dimruncycle where packagename = 'factRequestForDocuments' and success = 't'\")\n",
    "    df_existing.show()\n",
    "    maxcreatedate = df_existing.first().runcycleendat\n",
    "    print(maxcreatedate)\n",
    "    maxcreatedate_str = maxcreatedate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    df_existing = spark.sql(f\"SELECT distinct foiministryrequestid, min(foirequest_id) as foirequest_id from foi_mod.foiministryrequests where (created_at > '{maxcreatedate_str}' or TRY_CAST(updated_at AS DATE) > '{maxcreatedate_str}') group by foiministryrequestid\")\n",
    "\n",
    "    df_existing.show()\n",
    "\n",
    "    comma_list_df = df_existing.select(concat_ws(\",\", collect_list(\"foirequest_id\")).alias(\"comma_list\"))\n",
    "    comma_list = comma_list_df.collect()[0][\"comma_list\"]\n",
    "\n",
    "    print(comma_list)\n",
    "\n",
    "    query = f\"\"\"MERGE INTO default.factRequestForDocuments dd\n",
    "        --USING dimRequests r -- commented out since we are adding sourceoftruth column to each fact table\n",
    "        --ON r.foirequestid = dd.foirequestid\n",
    "        WHEN MATCHED and dd.foirequestid in ({comma_list}) and sourceoftruth = 'FOIMOD' THEN\n",
    "\n",
    "        UPDATE \n",
    "        SET dd.activeflag = 'N'\"\"\";\n",
    "\n",
    "    comma_list_df = df_existing.select(concat_ws(\",\", collect_list(\"foiministryrequestid\")).alias(\"comma_list\"))\n",
    "    comma_list = comma_list_df.collect()[0][\"comma_list\"]\n",
    "\n",
    "    print(comma_list)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        select * from\n",
    "\n",
    "        (SELECT *\n",
    "                FROM (\n",
    "                    SELECT \n",
    "                    case when requeststatuslabel = 'closed' then created_at else null end as completeddate,\n",
    "                    foiministryrequestid,\n",
    "                    foirequest_id,\n",
    "                    foirequestversion_id,\n",
    "                    version,\n",
    "                    duedate,\n",
    "                    description,\n",
    "                    axisrequestid,\n",
    "\n",
    "                    --*,\n",
    "                        ROW_NUMBER() OVER (\n",
    "                            PARTITION BY foiministryrequestid \n",
    "                            ORDER BY created_at DESC\n",
    "                        ) AS rn\n",
    "                    FROM foi_mod.foiministryrequests\n",
    "                    where foiministryrequestid in ({comma_list})\n",
    "                ) sub\n",
    "                WHERE rn = 1) sq\n",
    "\n",
    "        join \n",
    "\n",
    "        (select deliverymodeid, foirequestid, requesttype, version\n",
    "        from foi_mod.foirequests \n",
    "        ) r on r.foirequestid = sq.foirequest_id and r.version = sq.foirequestversion_id\n",
    "\n",
    "        join\n",
    "\n",
    "        (SELECT *\n",
    "                FROM (\n",
    "                    SELECT \n",
    "                    created_at as firstcreated_at,\n",
    "                    createdby,\n",
    "                    foiministryrequestid,\n",
    "                    --*,\n",
    "                        ROW_NUMBER() OVER (\n",
    "                            PARTITION BY foiministryrequestid \n",
    "                            ORDER BY created_at asc\n",
    "                        ) AS rn\n",
    "                    FROM foi_mod.foiministryrequests\n",
    "                ) sub\n",
    "                WHERE rn = 1) sq2 on sq2.foiministryrequestid = sq.foiministryrequestid\n",
    "\n",
    "\n",
    "        left join \n",
    "        (select description as subject, foiministryrequestid, foiministryrequestversion from foi_mod.subjectcodes\n",
    "        join foi_mod.foiministryrequestsubjectcodes using (subjectcodeid)) sq3 on sq.foiministryrequestid = sq3.foiministryrequestid \n",
    "        and sq.version = sq3.foiministryrequestversion\n",
    "        \"\"\"\n",
    "\n",
    "    print(query)\n",
    "\n",
    "    df = spark.sql(query)\n",
    "    print(df.count())\n",
    "    df.show()\n",
    "\n",
    "    if not df.isEmpty():\n",
    "        getdays = udf(getbusinessdaysbetween, IntegerType())\n",
    "\n",
    "        print(duedate_value)\n",
    "        print(type(duedate_value))\n",
    "\n",
    "        df = df.withColumn(\"overduedays\", getdays(lit(date.today()), df['duedate']))\n",
    "        df = df.withColumn(\"elapseddays\", getdays(lit(date.today()), df['firstcreated_at']))\n",
    "        df = df.withColumn(\"passduedays\", getdays(lit(date.today()), df['duedate']))\n",
    "        df = df.withColumn(\"remainingdays\", getdays(df['duedate'], lit(date.today())))\n",
    "\n",
    "        df.show(df.count(), truncate=False)\n",
    "\n",
    "\n",
    "\n",
    "        # order of columns here is important!\n",
    "        df_mapped = df.selectExpr(\n",
    "            \"NULL as actionid\",        \n",
    "            \"foirequest_id as foirequestid\",\n",
    "            f\"{runcycleid} as runcycleid\",\n",
    "            \"NULL as actiontype\",\n",
    "            \"description as description\",\n",
    "            \"'' as priority\",\n",
    "            \"'' as emailaddress\",\n",
    "            \"firstcreated_at as createddate\",\n",
    "            \"NULL as actiondate\",\n",
    "            \"duedate as duedate\",\n",
    "            \"'' AS responsedate\",\n",
    "            \"'' AS parentactionid\",\n",
    "            \"createdby AS createdby\",\n",
    "            \"subject AS subject\",\n",
    "            \"'' as programofficeid\",\n",
    "            \"'' AS reqfordocstatusid\",\n",
    "            \"completeddate AS completeddate\",\n",
    "            \"NULL AS requestofficeid\",\n",
    "            \"axisrequestid as visiblerequestid\",\n",
    "            \"description AS requestdescription\",\n",
    "            \"NULL as officeid\",\n",
    "            \"requesttype as requesttypeid\",\n",
    "            \"overduedays as overduedays\",\n",
    "            \"elapseddays as elapseddays\",\n",
    "            \"passduedays as passduedays\",\n",
    "            \"NULL as rfdage\",\n",
    "            \"remainingdays as remainingdays\",\n",
    "            \"deliverymodeid as methodofdelivery\",\n",
    "            \"'Y' AS activeflag\",\n",
    "            \"'FOIMOD' as sourceoftruth\"\n",
    "        )\n",
    "        df_mapped.show()\n",
    "        df_mapped.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"false\").insertInto(\"factrequestfordocuments\")\n",
    "    else:\n",
    "        print(\"No results found for the query.\")\n",
    "\n",
    "    etl_helpers.end_run_cycle(runcycleid, 't', \"factRequestForDocuments\")\n",
    "except NoCredentialsError:\n",
    "    print(\"Credentials not available\")\n",
    "    etl_helpers.end_run_cycle(runcycleid, 'f', \"factRequestForDocuments\", \"Credentials not available\")\n",
    "except Exception as e:    \n",
    "    if (str(e) == \"no changes for today\"):\n",
    "        # print(\"here\")\n",
    "        etl_helpers.end_run_cycle(runcycleid, 't', \"factRequestForDocuments\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")    \n",
    "        etl_helpers.end_run_cycle(runcycleid, 'f', \"factRequestForDocuments\", f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6227ebf7-c0e7-467f-8776-6f0d65de43c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "factRequestForDocumentsETL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
