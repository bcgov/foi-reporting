{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f14c953-83ba-4030-9b7e-72e1c00f6c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This ETL is for updating data into factrequestrfdcalculatedfields table. This ETL package is named as \"factRequestsRFSCalcFields\", to align with the pre-existing SSIS ETL for the same table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9269ab2-e30a-4e1f-a5ef-28dcdb77770a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%restart_python \n",
    "%pip install maya holidays python-dateutil pytz\n",
    "%pip install boto3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f47e067c-b574-44a9-ae8b-bc047aec839d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook for datetimehandler class\n",
    "\n",
    "import maya\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "\n",
    "class datetimehandler:\n",
    "    \"\"\"Supports common date operations\"\"\"\n",
    "\n",
    "    def gettoday(self, format=None):\n",
    "        now_pst = maya.parse(maya.now()).datetime(to_timezone=self.getdefaulttimezone(), naive=False)\n",
    "        return self.__formatdate(now_pst, format)\n",
    "\n",
    "    def now(self):\n",
    "        return maya.parse(maya.now()).datetime(to_timezone=self.getdefaulttimezone(), naive=False)\n",
    "    \n",
    "    def formatdate(self, input, format=None):\n",
    "        _inpdate = self.getdate(input)\n",
    "        return self.__formatdate(_inpdate, format) \n",
    "\n",
    "    def convert_to_pst(self, input, format=None):\n",
    "        now_pst = maya.parse(self.getdate(input)).datetime(to_timezone=self.getdefaulttimezone(), naive=False)\n",
    "        return self.__formatdate(now_pst, format) \n",
    "\n",
    "    def __formatdate(self, _inpdate, format):\n",
    "        _format = format if format not in (None, '') else self.getdefaultdateformat()\n",
    "        return _inpdate.strftime(_format)\n",
    "\n",
    "    def getdate(self, inputdate):\n",
    "        return datetime.strptime(inputdate, \"%Y-%m-%d\") if isinstance(inputdate, str) else inputdate            \n",
    "   \n",
    "    def getdefaulttimezone(self):\n",
    "        return 'America/Vancouver'\n",
    "\n",
    "    def getdefaultdateformat(self):\n",
    "        return '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4ebb73c-feb1-44ed-99d1-162a949b9820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook for duecalculator class\n",
    "\n",
    "from os import stat\n",
    "from re import VERBOSE\n",
    "from datetime import datetime as datetime2\n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "from pytz import timezone\n",
    "# Use the datetimehandler class defined above in this notebook\n",
    "\n",
    "class duecalculator:\n",
    "    \"\"\" Due date calculator helper service \"\"\"\n",
    "\n",
    "    def getpreviousbusinessday(self, cfrduedate, ca_holidays):\n",
    "        _prevbusinessday = self.__getpreviousweekday(cfrduedate)\n",
    "        if not self.__isholiday(_prevbusinessday, ca_holidays):            \n",
    "            return _prevbusinessday\n",
    "        else:\n",
    "            return self.getpreviousbusinessday(_prevbusinessday, ca_holidays)\n",
    "        \n",
    "    def getpreviousbusinessday_by_n(self, duedate, ca_holidays, n):\n",
    "        _prevbusinessday = duedate\n",
    "        for _ in range(n):\n",
    "            _prevbusinessday = self.getpreviousbusinessday(_prevbusinessday, ca_holidays)\n",
    "        return _prevbusinessday\n",
    "    \n",
    "    def formatduedate(self, input):\n",
    "        return datetimehandler().formatdate(input)\n",
    "\n",
    "    def addbusinessdays(self, inpdate, days):\n",
    "        _holidays = self.getholidays()\n",
    "        businessdays = 0\n",
    "        __calcdate = datetimehandler().getdate(inpdate)\n",
    "        while businessdays < days:\n",
    "            __calcdate += timedelta(days=1)\n",
    "            if self.isbusinessday(__calcdate, _holidays):\n",
    "                businessdays += 1              \n",
    "        return __calcdate\n",
    "\n",
    "    def getbusinessdaysbetween(self, date1, date2=None):\n",
    "        _holidays = self.getholidays()\n",
    "        businessdays = 0\n",
    "        date2 = date2 if date2 else self.gettoday()\n",
    "        _date1_date_fmt = datetimehandler().getdate(date1)\n",
    "        _date2_date_fmt = datetimehandler().getdate(date2)\n",
    "        __fromdate = min(_date1_date_fmt, _date2_date_fmt)\n",
    "        __todate = max(_date1_date_fmt, _date2_date_fmt)\n",
    "        __fromcalcdate = __fromdate\n",
    "        while __fromcalcdate.date() < __todate.date():\n",
    "            if self.isbusinessday(__fromcalcdate, _holidays):\n",
    "                businessdays += 1\n",
    "            __fromcalcdate += timedelta(days=1)           \n",
    "        return businessdays  \n",
    "\n",
    "    def getholidays(self):\n",
    "        ca_holidays = []\n",
    "        currentyear = datetime.today().year\n",
    "        years = [currentyear - 1, currentyear, currentyear + 1] \n",
    "        for year in years:\n",
    "            ca_holidays.extend(self.__getholidaysbyyear(year))\n",
    "        return ca_holidays\n",
    "\n",
    "    def gettoday(self):\n",
    "        return datetimehandler().gettoday()\n",
    "\n",
    "    def now(self):\n",
    "        return datetimehandler().now()\n",
    "\n",
    "    def __getholidaysbyyear(self, year):        \n",
    "        ca_holidays = []\n",
    "        for date, name in sorted(holidays.CA(prov='BC', years=year).items()):\n",
    "            ca_holidays.append(date.strftime(datetimehandler().getdefaultdateformat()))\n",
    "        if 'FOI_ADDITIONAL_HOLIDAYS' in os.environ and os.getenv('FOI_ADDITIONAL_HOLIDAYS'):\n",
    "            _addldays = os.getenv('FOI_ADDITIONAL_HOLIDAYS')\n",
    "            for _addlday in _addldays.split(\",\"):\n",
    "                ca_holidays.append(_addlday.strip().replace('XXXX', str(year)))\n",
    "        return ca_holidays    \n",
    "\n",
    "    def isbusinessday(self, inpdate, holidays=None):\n",
    "        _holidays = self.getholidays() if holidays is None else holidays\n",
    "        if datetimehandler().formatdate(inpdate) not in _holidays and self.__isweekday(inpdate):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __isweekday(self, inpdate):\n",
    "        _inpdate = datetimehandler().getdate(inpdate)\n",
    "        return _inpdate.weekday() < 5\n",
    "    \n",
    "    def __getpreviousweekday(self, cfrduedate):\n",
    "        _cfrduedate = datetimehandler().getdate(cfrduedate)  \n",
    "        if _cfrduedate.weekday() == 0:\n",
    "            diff = 3\n",
    "        elif _cfrduedate.weekday() == 6:\n",
    "            diff = 2\n",
    "        else:\n",
    "            diff = 1  \n",
    "        res = _cfrduedate - timedelta(days=diff)\n",
    "        return res.strftime(datetimehandler().getdefaultdateformat())           \n",
    "   \n",
    "    def __isholiday(self, input, ca_holidays):\n",
    "        return input in ca_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb14372-76d4-4ae1-acb8-59eb1b810dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import date\n",
    "from pyspark.sql.functions import udf, col,to_date\n",
    "from pyspark.sql.types import IntegerType, BooleanType\n",
    "import sys\n",
    "sys.path.insert(0, '/Workspace/Shared')\n",
    "import etl_helpers\n",
    " \n",
    "\n",
    "def business_days_fromtoday(duedate):\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\n",
    "    try:\n",
    "        return duecalculator().getbusinessdaysbetween(duedate, today)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def business_days_between(date1, date2):\n",
    "    try:\n",
    "        if date1 == None or date1 == 'NULL':\n",
    "            return 0            \n",
    "        result  = duecalculator().getbusinessdaysbetween(date1, date2)            \n",
    "        return result   \n",
    "    except Exception:\n",
    "        return None    \n",
    "\n",
    "try:\n",
    "   \n",
    "    tablename = \"factrequestrfdcalculatedfields\"\n",
    "    runcycleid = etl_helpers.start_run_cycle(f\"{tablename}\")\n",
    "    os.makedirs(\"/dbfs/foi/dataload\", exist_ok=True)  # make sure directory exists\n",
    "\n",
    "  \n",
    "\n",
    "    df_lastrun = spark.sql(f\"SELECT runcyclestartat as createddate FROM dimruncycle WHERE packagename = \\\"{tablename}\\\" AND success = 't' ORDER BY runcycleid DESC LIMIT 1\")\n",
    "        \n",
    "    if df_lastrun.count() > 0:\n",
    "        lastruntime = df_lastrun.first().createddate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        lastruntime = \"2019-01-01 00:00:00\"\n",
    "        print(lastruntime)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            frs.name as requeststatus,\n",
    "            {runcycleid} as runcycleid,\n",
    "            MIN(fmr.foirequest_id) AS foirequestid,\n",
    "            MIN(fmr.startdate) AS startdate,\n",
    "            MIN(fmr.duedate) AS duedate,\n",
    "            MIN(fmr.cfrduedate) AS cfrduedate,           \n",
    "            MIN(fmr.created_at) AS createdat,\n",
    "            MIN(fmr.updated_at) AS updatedat,\n",
    "            now() as todaydate\n",
    "        FROM foi_mod.foiministryrequests fmr\n",
    "            JOIN foi_mod.foirequeststatuses frs ON fmr.requeststatusid = frs.requeststatusid\n",
    "            WHERE fmr.created_at > '{lastruntime}'\n",
    "            GROUP BY frs.name\n",
    "            ORDER BY MIN(fmr.created_at)\n",
    "            \"\"\"\n",
    "\n",
    "    df = spark.sql(query)\n",
    "    # df.show()\n",
    "\n",
    "    df_mapped = df.selectExpr(\n",
    "        \"foirequestid AS foirequestid\",\n",
    "        \"runcycleid AS runcycleid\",\n",
    "        \"requeststatus as requeststatus\",\n",
    "        \"startdate AS startdate\",\n",
    "        \"duedate AS duedate\",        \n",
    "        \"cfrduedate AS cfrduedate\",\n",
    "        \"createdat AS createdat\",\n",
    "        \"updatedat AS updatedat\",\n",
    "        \"todaydate AS todaydate\"\n",
    "    )\n",
    "       \n",
    "    df_mapped.show()\n",
    "\n",
    "    \n",
    "\n",
    "    business_days_fromtodayudf = udf(business_days_fromtoday, IntegerType())\n",
    "    business_days_between_udf = udf(business_days_between, IntegerType())\n",
    "\n",
    "\n",
    "    df_transformed = df_mapped \\\n",
    "    .withColumn(\"overduedays\", business_days_fromtodayudf(col(\"duedate\")))\\\n",
    "    .withColumn(\"elapseddays\", business_days_between_udf(col(\"startdate\"), col(\"todaydate\")))\\\n",
    "    .withColumn(\"passduedays\", business_days_between_udf(col(\"duedate\"), col(\"todaydate\")))\\\n",
    "    .withColumn(\"remainingdays\", business_days_between_udf(col(\"todaydate\"), col(\"duedate\")))\\\n",
    "    .withColumn(\"rfdage\", business_days_between_udf(col(\"todaydate\"), col(\"cfrduedate\")))\n",
    "   \n",
    "   \n",
    "  \n",
    "    df_load_data =  df_transformed.select(\"foirequestid\",\"runcycleid\" , \"overduedays\", \"elapseddays\", \"passduedays\",  \"rfdage\",\"remainingdays\",\"requeststatus\")\n",
    "    df_load_data.show()\n",
    "\n",
    "    from delta.tables import DeltaTable\n",
    "    delta_table = DeltaTable.forName(spark, f\"hive_metastore.default.{tablename}\")\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        df_load_data.alias(\"source\"),\n",
    "        \"target.foirequestid = source.foirequestid\"\n",
    "    ).whenNotMatchedInsert(values = {\n",
    "        \"foirequestid\": \"source.foirequestid\",\n",
    "        \"runcycleid\": \"source.runcycleid\",\n",
    "        \"overduedays\": \"source.overduedays\",\n",
    "        \"elapseddays\": \"source.elapseddays\",\n",
    "        \"passduedays\": \"source.passduedays\",\n",
    "        \"rfdage\": \"source.rfdage\",\n",
    "        \"remainingdays\": \"source.remainingdays\",\n",
    "        \"requeststatus\":\"source.requeststatus\"\n",
    "    }).execute()\n",
    "\n",
    "    etl_helpers.end_run_cycle(runcycleid, 't', f\"{tablename}\")\n",
    "except NoCredentialsError:\n",
    "    print(\"Credentials not available\")\n",
    "    etl_helpers.end_run_cycle(runcycleid, 'f', f\"{tablename}\", \"Credentials not available\")\n",
    "except Exception as e:\n",
    "    if (str(e) == \"no changes for today\"):\n",
    "        print(\"here\")\n",
    "        etl_helpers.end_run_cycle(runcycleid, 't', f\"{tablename}\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")    \n",
    "        etl_helpers.end_run_cycle(runcycleid, 'f', f\"{tablename}\", f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "factRequestsRFSCalcFields",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
