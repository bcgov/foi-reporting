{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5066fd-ef21-4d97-8d9d-e45749e4fa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python\n",
    "%pip install boto3\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from pyspark.sql import functions as F\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.insert(0, '/Workspace/Shared')\n",
    "import etl_helpers \n",
    "from pyspark.sql.functions import collect_list, concat_ws\n",
    "\n",
    "runcycleid = etl_helpers.start_run_cycle(\"factRequestDocumentsDetails\")\n",
    "\n",
    "os.makedirs(\"/dbfs/foi/dataload\", exist_ok=True)  # make sure directory exists\n",
    "\n",
    "try:\n",
    "    today = str(datetime.date.today())\n",
    "\n",
    "    df_existing = spark.sql(\"SELECT max(TIMESTAMP(runcycleendat)) as runcycleendat from dimruncycle where packagename = 'factRequestDocumentsDetails' and success = 't'\")\n",
    "    df_existing.show()\n",
    "    maxcreatedate = df_existing.first().runcycleendat\n",
    "    print(maxcreatedate)\n",
    "    maxcreatedate_str = maxcreatedate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    df_existing = spark.sql(f\"SELECT distinct foiministryrequestid, min(foirequest_id) as foirequest_id from foi_mod.foiministryrequests where (created_at > '{maxcreatedate_str}' or DATE(updated_at) > '{maxcreatedate_str}') group by foiministryrequestid\")\n",
    "\n",
    "    df_existing.show()\n",
    "\n",
    "    comma_list_df = df_existing.select(concat_ws(\",\", collect_list(\"foirequest_id\")).alias(\"comma_list\"))\n",
    "    comma_list = comma_list_df.collect()[0][\"comma_list\"]\n",
    "\n",
    "    \n",
    "\n",
    "    print(comma_list)\n",
    "\n",
    "    if comma_list == \"\":\n",
    "        raise Exception(\"no changes for today\")\n",
    "\n",
    "    query = f\"\"\"MERGE INTO default.factRequestDocumentsDetails dd\n",
    "        USING dimRequests r\n",
    "        ON r.foirequestid = dd.foirequestid\n",
    "        WHEN MATCHED and dd.foirequestid in ({comma_list}) and sourceoftruth = 'FOIMOD' THEN\n",
    "\n",
    "        UPDATE \n",
    "        SET dd.activeflag = 'N'\"\"\";\n",
    "\n",
    "        \n",
    "    comma_list_df = df_existing.select(concat_ws(\",\", collect_list(\"foiministryrequestid\")).alias(\"comma_list\"))\n",
    "    comma_list = comma_list_df.collect()[0][\"comma_list\"]\n",
    "\n",
    "    query = f\"\"\"\n",
    "        select sq1.foiministryrequestid, count, \n",
    "        case when requeststatuslabel = 'closed' then count else 0 end as pagesreleased,\n",
    "        sq2.created_at, sq2.updated_at, sq2.foirequest_id,\n",
    "\n",
    "        estimatedelectronicpages, estimatedhardcopypages,\n",
    "        pagecount, dedupepagecount\n",
    "        from \n",
    "        ((select foiministryrequestid, count(*) as count\n",
    "        from (\n",
    "        select \n",
    "        EXPLODE(\n",
    "            FROM_JSON(\n",
    "                pageflag,\n",
    "                'ARRAY<STRUCT<flagid: INT, page: INT, programareaid: ARRAY<INT>, other: ARRAY<STRING>>>'\n",
    "            )\n",
    "            ) as pageflags,\n",
    "        -- explode(split(pageflag, ',')) as pageflags,\n",
    "        -- pageflag, \n",
    "        dpf.foiministryrequestid from docreviewer.documentpageflags dpf\n",
    "        join docreviewer.documents d on dpf.documentid = d.documentid\n",
    "        join docreviewer.documentmaster dm on dm.documentmasterid = d.documentmasterid\n",
    "        left join docreviewer.documentdeleted dd on dd.filepath || '%' ilike dm.filepath\n",
    "        where dd.deleted is null or dd.deleted is false\n",
    "        )\n",
    "        group by foiministryrequestid ) sq1\n",
    "\n",
    "        join (WITH ranked AS (\n",
    "        SELECT *,\n",
    "                ROW_NUMBER() OVER (PARTITION BY foiministryrequestid ORDER BY version DESC) AS rn\n",
    "        FROM foi_mod.FOIMinistryRequests fmr\n",
    "        )\n",
    "        SELECT ranked.foiministryrequestid, ranked.requeststatuslabel, ranked.created_at, ranked.updated_at, ranked.foirequest_id\n",
    "        FROM ranked\n",
    "        WHERE rn = 1 and (foiministryrequestid in ({comma_list}))) sq2 on sq1.foiministryrequestid = sq2.foiministryrequestid)\n",
    "        left join\n",
    "\n",
    "        (WITH ranked AS (\n",
    "        SELECT ministryrequestid, get_json_object(feedata, '$.estimatedelectronicpages') AS estimatedelectronicpages,\n",
    "        get_json_object(feedata, '$.estimatedhardcopypages') AS estimatedhardcopypages,\n",
    "                ROW_NUMBER() OVER (PARTITION BY cfrfeeid ORDER BY version DESC) AS rn\n",
    "        FROM foi_mod.foirequestcfrfees\n",
    "        )\n",
    "        SELECT *\n",
    "        FROM ranked\n",
    "        WHERE rn = 1) sq3 on sq3.ministryrequestid = sq1.foiministryrequestid\n",
    "\n",
    "        join (\n",
    "\n",
    "        select sq3.*, sq2.dedupepagecount from \n",
    "        (select foiministryrequestid, sum(pagecount) as pagecount from docreviewer.documents d\n",
    "        group by foiministryrequestid) sq3\n",
    "        join\n",
    "\n",
    "        (select sum(pagecount) as dedupepagecount, foiministryrequestid from docreviewer.documents d1\n",
    "        join \n",
    "        (select rank1hash, min(d.documentid) as docid  from docreviewer.documenthashcodes dhc\n",
    "        join docreviewer.documents d on d.documentid = dhc.documentid\n",
    "        group by rank1hash) sq on sq.docid = d1.documentid\n",
    "        group by foiministryrequestid) sq2 on sq2.foiministryrequestid = sq3.foiministryrequestid) sq4 on sq4.foiministryrequestid = sq1.foiministryrequestid\n",
    "        \"\"\"\n",
    "\n",
    "    print(query)\n",
    "\n",
    "    df = spark.sql(query)\n",
    "    df.show()\n",
    "\n",
    "\n",
    "    # order of columns here is important!\n",
    "    df_mapped = df.selectExpr(\n",
    "        \"foirequest_id AS foirequestid\",\n",
    "        f\"{runcycleid} as runcycleid\",\n",
    "        \"count AS noofpagesreviewed\",\n",
    "        \"pagesreleased AS noofpagesreleased\",\n",
    "        \"dedupepagecount AS noofpagesdeduplicated\",\n",
    "        \"NULL AS noofpagesintherequest\",\n",
    "        \"estimatedelectronicpages AS electronicpageestimate\",\n",
    "        \"estimatedhardcopypages AS physicalpageestimate\",\n",
    "        \"'' AS noofpagesinreviewlog\",\n",
    "        \"'' AS noofpagesinredactionlayer\",\n",
    "        \"'Y' AS activeflag\",\n",
    "    )\n",
    "    df_mapped.show()\n",
    "    df_mapped.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"false\").insertInto(\"factrequestdocumentsdetails\")  \n",
    "    etl_helpers.end_run_cycle(runcycleid, 't', \"factRequestDocumentsDetails\")\n",
    "except NoCredentialsError:\n",
    "    print(\"Credentials not available\")\n",
    "    etl_helpers.end_run_cycle(runcycleid, 'f', \"factRequestDocumentsDetails\", \"Credentials not available\")\n",
    "    raise Exception(\"notebook failed\") from e\n",
    "except Exception as e:\n",
    "    if (str(e) == \"no changes for today\"):\n",
    "        print(\"here\")\n",
    "        etl_helpers.end_run_cycle(runcycleid, 't', \"factRequestDocumentsDetails\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")    \n",
    "        etl_helpers.end_run_cycle(runcycleid, 'f', \"factRequestDocumentsDetails\", f\"An error occurred: {e}\")\n",
    "        raise Exception(\"notebook failed\") from e"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "factRequestDocumentsDetailsETL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
